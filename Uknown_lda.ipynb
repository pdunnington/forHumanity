{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import spacy\n",
    "\n",
    "#gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = pd.read_csv('/Users/patrickdunnington/Desktop/DS_Capstone/msds_capstone_2024/personal_notebooks/patrick_nb/mongodump_full_snapshot_4_8/reports.csv')\n",
    "df_incident = pd.read_csv('/Users/patrickdunnington/Desktop/DS_Capstone/msds_capstone_2024/personal_notebooks/patrick_nb/mongodump_full_snapshot_4_8/incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alleged developer of AI system\n",
      "[\"unknown\"]     90\n",
      "[\"tesla\"]       44\n",
      "[\"facebook\"]    36\n",
      "[\"openai\"]      29\n",
      "[\"google\"]      28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_incident['Alleged developer of AI system'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix the format of the 'Alleged deployer of AI system' column\n",
    "# df_incident['Alleged deployer of AI system'] = df_incident['Alleged deployer of AI system'].apply(lambda x: ', '.join(eval(x)))\n",
    "\n",
    "# # Fix the format of the 'Alleged developer of AI system' column\n",
    "# df_incident['Alleged developer of AI system'] = df_incident['Alleged developer of AI system'].apply(lambda x: ', '.join(eval(x)))\n",
    "\n",
    "# # Fix the format of the 'Alleged harmed or nearly harmed parties' column\n",
    "# df_incident['Alleged harmed or nearly harmed parties'] = df_incident['Alleged harmed or nearly harmed parties'].apply(lambda x: ', '.join(eval(x)))\n",
    "\n",
    "# # Display the DataFrame after fixing the format\n",
    "# df_incident.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_rows = df_incident[df_incident['Alleged developer of AI system'] == '[\"unknown\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>incident_id</th>\n",
       "      <th>date</th>\n",
       "      <th>reports</th>\n",
       "      <th>Alleged deployer of AI system</th>\n",
       "      <th>Alleged developer of AI system</th>\n",
       "      <th>Alleged harmed or nearly harmed parties</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ObjectId(625763df343edc875fe63a1d)</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>[454,455,456,457,458,459,460,461,462,463,464,4...</td>\n",
       "      <td>[\"delhi-metro-rail-corporation\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"delhi-metro-rail-corporation\"]</td>\n",
       "      <td>A driverless metro train in Delhi, India crash...</td>\n",
       "      <td>Driverless Train in Delhi Crashes due to Braki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ObjectId(625763df343edc875fe63a21)</td>\n",
       "      <td>35</td>\n",
       "      <td>2014-10-18</td>\n",
       "      <td>[539,540,541,543,544,545,547,548,549,550,551,5...</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"ibrahim-diallo\"]</td>\n",
       "      <td>An employee was laid off, allegedly by an arti...</td>\n",
       "      <td>Employee Automatically Terminated by Computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ObjectId(625763e3343edc875fe63a43)</td>\n",
       "      <td>69</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>[1240,1241,1243,1244,1245,1246,1247,1248,1249,...</td>\n",
       "      <td>[\"skh-metals\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"ramji-lal\"]</td>\n",
       "      <td>A factory robot at the SKH Metals Factory in M...</td>\n",
       "      <td>Worker killed by robot in welding accident at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ObjectId(625763e4343edc875fe63a4a)</td>\n",
       "      <td>76</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>[1339]</td>\n",
       "      <td>[\"buenos-aires-city-government\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"buenos-aires-children\"]</td>\n",
       "      <td>Buenos Aires city government uses a facial rec...</td>\n",
       "      <td>Live facial recognition is tracking kids suspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ObjectId(625763e4343edc875fe63a4e)</td>\n",
       "      <td>80</td>\n",
       "      <td>2020-10-24</td>\n",
       "      <td>[1380,1559]</td>\n",
       "      <td>[\"inverness-caledonian-thistle-football-club\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"livestream-viewers\"]</td>\n",
       "      <td>In a Scottish soccer match the AI-enabled ball...</td>\n",
       "      <td>AI mistakes referee’s bald head for football —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>ObjectId(65725d1e1c8e14919a805a45)</td>\n",
       "      <td>616</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>[3448,3452,3453,3454,3455,3456,3457,3458,3459,...</td>\n",
       "      <td>[\"the-arena-group\",\"sports-illustrated\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"general-public\",\"readers-of-sports-illustrat...</td>\n",
       "      <td>Sports Illustrated, managed by The Arena Group...</td>\n",
       "      <td>Sports Illustrated Is Alleged to Have Used AI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>ObjectId(65844bb96716ef9da676462f)</td>\n",
       "      <td>617</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>[3495]</td>\n",
       "      <td>[\"unnamed-male-student\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"anonymous-female-high-school-students\"]</td>\n",
       "      <td>At a high school in Issaquah, Washington, a ma...</td>\n",
       "      <td>Male student allegedly used AI to generate nud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ObjectId(65ae967aa040369f2c75ab5b)</td>\n",
       "      <td>628</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>[3602,3608]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"president-joe-biden\",\"new-hampshire-voters\",...</td>\n",
       "      <td>A robocall imitating President Joe Biden's voi...</td>\n",
       "      <td>Fake Biden Voice in Robocall Misleads New Hamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>ObjectId(65e362fb67df8539735d3f7f)</td>\n",
       "      <td>648</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>[3753,3758]</td>\n",
       "      <td>[\"unknown-social-media-accounts\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"voters-in-pakistan\",\"imran-khan\",\"pti-(pakis...</td>\n",
       "      <td>A purported deepfake audio clip, falsely attri...</td>\n",
       "      <td>Alleged Deepfake Audio of Imran Khan Calls for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>ObjectId(65e3652c4139cb7c36eefb96)</td>\n",
       "      <td>649</td>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>[3754]</td>\n",
       "      <td>[\"various-social-media-accounts\"]</td>\n",
       "      <td>[\"unknown\"]</td>\n",
       "      <td>[\"general-public\",\"british-voters\",\"british-la...</td>\n",
       "      <td>A deepfake audio clip, falsely claiming to be ...</td>\n",
       "      <td>Deepfake Audio Falsely Attributes Controversia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id  incident_id        date  \\\n",
       "30   ObjectId(625763df343edc875fe63a1d)           31  2017-12-03   \n",
       "34   ObjectId(625763df343edc875fe63a21)           35  2014-10-18   \n",
       "68   ObjectId(625763e3343edc875fe63a43)           69  2015-07-02   \n",
       "75   ObjectId(625763e4343edc875fe63a4a)           76  2020-10-09   \n",
       "79   ObjectId(625763e4343edc875fe63a4e)           80  2020-10-24   \n",
       "..                                  ...          ...         ...   \n",
       "604  ObjectId(65725d1e1c8e14919a805a45)          616  2023-11-27   \n",
       "605  ObjectId(65844bb96716ef9da676462f)          617  2023-11-09   \n",
       "616  ObjectId(65ae967aa040369f2c75ab5b)          628  2024-01-22   \n",
       "636  ObjectId(65e362fb67df8539735d3f7f)          648  2024-02-07   \n",
       "637  ObjectId(65e3652c4139cb7c36eefb96)          649  2024-02-14   \n",
       "\n",
       "                                               reports  \\\n",
       "30   [454,455,456,457,458,459,460,461,462,463,464,4...   \n",
       "34   [539,540,541,543,544,545,547,548,549,550,551,5...   \n",
       "68   [1240,1241,1243,1244,1245,1246,1247,1248,1249,...   \n",
       "75                                              [1339]   \n",
       "79                                         [1380,1559]   \n",
       "..                                                 ...   \n",
       "604  [3448,3452,3453,3454,3455,3456,3457,3458,3459,...   \n",
       "605                                             [3495]   \n",
       "616                                        [3602,3608]   \n",
       "636                                        [3753,3758]   \n",
       "637                                             [3754]   \n",
       "\n",
       "                      Alleged deployer of AI system  \\\n",
       "30                 [\"delhi-metro-rail-corporation\"]   \n",
       "34                                      [\"unknown\"]   \n",
       "68                                   [\"skh-metals\"]   \n",
       "75                 [\"buenos-aires-city-government\"]   \n",
       "79   [\"inverness-caledonian-thistle-football-club\"]   \n",
       "..                                              ...   \n",
       "604        [\"the-arena-group\",\"sports-illustrated\"]   \n",
       "605                        [\"unnamed-male-student\"]   \n",
       "616                                     [\"unknown\"]   \n",
       "636               [\"unknown-social-media-accounts\"]   \n",
       "637               [\"various-social-media-accounts\"]   \n",
       "\n",
       "    Alleged developer of AI system  \\\n",
       "30                     [\"unknown\"]   \n",
       "34                     [\"unknown\"]   \n",
       "68                     [\"unknown\"]   \n",
       "75                     [\"unknown\"]   \n",
       "79                     [\"unknown\"]   \n",
       "..                             ...   \n",
       "604                    [\"unknown\"]   \n",
       "605                    [\"unknown\"]   \n",
       "616                    [\"unknown\"]   \n",
       "636                    [\"unknown\"]   \n",
       "637                    [\"unknown\"]   \n",
       "\n",
       "               Alleged harmed or nearly harmed parties  \\\n",
       "30                    [\"delhi-metro-rail-corporation\"]   \n",
       "34                                  [\"ibrahim-diallo\"]   \n",
       "68                                       [\"ramji-lal\"]   \n",
       "75                           [\"buenos-aires-children\"]   \n",
       "79                              [\"livestream-viewers\"]   \n",
       "..                                                 ...   \n",
       "604  [\"general-public\",\"readers-of-sports-illustrat...   \n",
       "605          [\"anonymous-female-high-school-students\"]   \n",
       "616  [\"president-joe-biden\",\"new-hampshire-voters\",...   \n",
       "636  [\"voters-in-pakistan\",\"imran-khan\",\"pti-(pakis...   \n",
       "637  [\"general-public\",\"british-voters\",\"british-la...   \n",
       "\n",
       "                                           description  \\\n",
       "30   A driverless metro train in Delhi, India crash...   \n",
       "34   An employee was laid off, allegedly by an arti...   \n",
       "68   A factory robot at the SKH Metals Factory in M...   \n",
       "75   Buenos Aires city government uses a facial rec...   \n",
       "79   In a Scottish soccer match the AI-enabled ball...   \n",
       "..                                                 ...   \n",
       "604  Sports Illustrated, managed by The Arena Group...   \n",
       "605  At a high school in Issaquah, Washington, a ma...   \n",
       "616  A robocall imitating President Joe Biden's voi...   \n",
       "636  A purported deepfake audio clip, falsely attri...   \n",
       "637  A deepfake audio clip, falsely claiming to be ...   \n",
       "\n",
       "                                                 title  \n",
       "30   Driverless Train in Delhi Crashes due to Braki...  \n",
       "34   Employee Automatically Terminated by Computer ...  \n",
       "68   Worker killed by robot in welding accident at ...  \n",
       "75   Live facial recognition is tracking kids suspe...  \n",
       "79   AI mistakes referee’s bald head for football —...  \n",
       "..                                                 ...  \n",
       "604  Sports Illustrated Is Alleged to Have Used AI ...  \n",
       "605  Male student allegedly used AI to generate nud...  \n",
       "616  Fake Biden Voice in Robocall Misleads New Hamp...  \n",
       "636  Alleged Deepfake Audio of Imran Khan Calls for...  \n",
       "637  Deepfake Audio Falsely Attributes Controversia...  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/9y5tt5gx6jsc140h_cssjx1m0000gn/T/ipykernel_2063/1356619043.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isolated_rows['date'] = pd.to_datetime(isolated_rows['date'])\n",
      "/var/folders/4b/9y5tt5gx6jsc140h_cssjx1m0000gn/T/ipykernel_2063/1356619043.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isolated_rows['clean_description'] = isolated_rows['description'].str.replace('ai', '').str.replace('AI', '')\n",
      "/Users/patrickdunnington/anaconda3/envs/bayesml/lib/python3.11/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import spacy\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# Convert date column to datetime format\n",
    "isolated_rows['date'] = pd.to_datetime(isolated_rows['date'])\n",
    "\n",
    "# Clean dataset\n",
    "# for i in range(1, 565):\n",
    "#     isolated_rows.loc[i, 'reportnumber'] = isolated_rows.loc[i, 'reports'].count(\",\") + 1\n",
    "\n",
    "# Clean description column\n",
    "isolated_rows['clean_description'] = isolated_rows['description'].str.replace('ai', '').str.replace('AI', '')\n",
    "\n",
    "def lemmatization(incidents, allowed_postags=[\"NOUN\",\"ADJ\",\"VERB\",\"ADV\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable = [\"parser\", \"ner\"])\n",
    "    descript_out = []\n",
    "    for incident in incidents:\n",
    "        doc = nlp(incident)\n",
    "        new_descript = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_descript.append(token.lemma_)\n",
    "        final = ' '.join(new_descript)\n",
    "        descript_out.append(final)      \n",
    "    return (descript_out) \n",
    "\n",
    "lemmatized_decript = lemmatization(isolated_rows['clean_description'])\n",
    "\n",
    "def gen_words(incidents):\n",
    "    final = []\n",
    "    for incident in incidents:\n",
    "        new = gensim.utils.simple_preprocess(incident, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_decript)\n",
    "\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for incident in data_words:\n",
    "    new = id2word.doc2bow(incident)\n",
    "    corpus.append(new)\n",
    "\n",
    "# print(corpus[0][0:20])\n",
    "\n",
    "word = id2word[[0][:1][0]]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=20,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto')\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds', R=30)\n",
    "pyLDAvis.save_html(vis, '/Users/patrickdunnington/Desktop/DS_Capstone/msds_capstone_2024/personal_notebooks/patrick_nb/ldavisual_unknown.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: author, content, employe, notic, websit, twitter, ceo, manag, compani, remov\n",
      "Topic 2: face, use, report, voic, alleg, high, resid, plate, suspect, system\n",
      "Topic 3: video, use, minor, imag, report, alleg, voic, creat, tatum, post\n",
      "Topic 4: use, facial, recognit, system, arrest, social, firm, media, post, depart\n",
      "Topic 5: imag, technolog, alleg, recognit, man, use, arrest, potenti, facial, theft\n",
      "Topic 6: alleg, fake, face, clip, polit, deepfak, audio, circul, thousand, custom\n",
      "Topic 7: softwar, elect, fals, black, deepfak, report, audio, social, media, breach\n",
      "Topic 8: use, student, deepfak, voic, school, data, new, video, facial, like\n",
      "Topic 9: robot, factori, lal, machin, metal, reach, soccer, prompt, make, handl\n",
      "Topic 10: deepfak, alleg, video, use, post, polic, technolog, due, imag, ukrnian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/9y5tt5gx6jsc140h_cssjx1m0000gn/T/ipykernel_2063/3673670255.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isolated_rows['clean_description'] = isolated_rows['clean_description'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "isolated_rows['clean_description'] = isolated_rows['clean_description'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "incident_DTM = vectorizer.fit_transform(isolated_rows['clean_description'])\n",
    "\n",
    "# Perform LDA\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=321)\n",
    "incident_topics = lda.fit_transform(incident_DTM)\n",
    "\n",
    "# Print top terms for each topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_terms = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
    "    print(f\"Topic {topic_idx + 1}: {', '.join(top_terms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
